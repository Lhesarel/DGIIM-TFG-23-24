{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "778177cf",
   "metadata": {},
   "source": [
    "# RECONOCIMIENTO DE TONOS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eebfb29",
   "metadata": {},
   "source": [
    "Primera aproximación: Hallar la nota más presente, máximo de la fft, en cada ventana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0438b618",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from scipy.fftpack import fft\n",
    "from scipy.io import wavfile # get the api\n",
    "import os\n",
    "import seaborn as sns\n",
    "# From V8\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks,correlate\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8285fb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "PATH = 'C:\\\\Users\\\\Javier\\\\Desktop\\\\TFG\\\\ReconocimientoDeTonos'      # Path of project's directory\n",
    "AUDIO_FILE = 'DoM-piano.wav'                                    # Audio file's name\n",
    "WINDOW_SIZE_SECS = 0.2                                               # Size of the fft window in seconds\n",
    "OVERLAPPING_SECS = 0.15                                              # Window's overlapping in seconds\n",
    "INTENSITY_THRESHOLD = 0.001                                          # Intensity (relevance) threshold for frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6d1be9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample rate: 44100 Hz\n",
      "Signal: [0.01104736 0.01083374 0.01083374 ... 0.         0.         0.        ]\n",
      "Window size: 0.2 s = 8820 samples\n",
      "Overlapping: 0.15 s = 6615 samples\n",
      "Audio length: 13.933469387755101 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-7c3418ec4c51>:4: WavFileWarning: Chunk (non-data) not understood, skipping it.\n",
      "  SAMPLE_RATE, data = wavfile.read(os.path.join(PATH,AUDIO_FILE))      # Get sample rate (samples per second) and signal data\n"
     ]
    }
   ],
   "source": [
    "# Global variables and files' statistics\n",
    "NOTES = [\"C\",\"C#\",\"D\",\"D#\",\"E\",\"F\",\"F#\",\"G\",\"G#\",\"A\",\"A#\",\"B\"]       # The twelve notes' names\n",
    "\n",
    "SAMPLE_RATE, data = wavfile.read(os.path.join(PATH,AUDIO_FILE))      # Get sample rate (samples per second) and signal data\n",
    "signal = data if data.ndim == 1 else data.T[0]                       # Get the first channel\n",
    "WINDOW_SIZE_SAMPLES = int(SAMPLE_RATE * WINDOW_SIZE_SECS)            # Size of the fft window in samples\n",
    "OVERLAPPING_SAMPLES = int(SAMPLE_RATE * OVERLAPPING_SECS)            # Size of overlapping in samples\n",
    "AUDIO_SIZE_SECS = len(signal) / SAMPLE_RATE                          # Size of the audio file in seconds\n",
    "\n",
    "print(\"Sample rate: \" + str(SAMPLE_RATE) + \" Hz\")                   \n",
    "print(\"Signal: \" + str(signal))                                      \n",
    "print(\"Window size: \" + str(WINDOW_SIZE_SECS) + \" s = \" + str(WINDOW_SIZE_SAMPLES) + \" samples\")\n",
    "print(\"Overlapping: \" + str(OVERLAPPING_SECS) + \" s = \" + str(OVERLAPPING_SAMPLES) + \" samples\")\n",
    "print(\"Audio length: \" + str(AUDIO_SIZE_SECS) + \" s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1198071d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions 1\n",
    "def graph2D(x,y,file):\n",
    "    rcParams['font.family'] = 'Book Antiqua'\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(x,y,label='Módulo de la FFT',color='black')\n",
    "    ax.set_title('Densidad espectral de potencia')\n",
    "    ax.set_xlabel('Frecuencias')\n",
    "    ax.set_ylabel('Intensidad')\n",
    "    ax.grid(True);\n",
    "    fig.savefig(file)\n",
    "    plt.close(fig)\n",
    "    \n",
    "def graph2D_old(X,Y,file):\n",
    "    plt.figure()\n",
    "    sns.set_style('darkgrid')\n",
    "    sns.lineplot(x=X,y=Y,color='black')\n",
    "    plt.savefig(file)\n",
    "    plt.close()\n",
    "\n",
    "def freq_to_number(f):                                                      # Transforms any note's frequency into its midi number \n",
    "    return 69 + 12*np.log2(f/440.0)    \n",
    "\n",
    "def number_to_freq(n):                                                      # Transforms any note's midi number into its frequency\n",
    "    return 440 * 2.0**((n-69)/12.0)\n",
    "\n",
    "def note_name(n):                                                           # Gets the note's name given its midi number\n",
    "    return NOTES[n % 12] + str(int(n/12 - 1))\n",
    "\n",
    "def extract_window(audio, window_number):                                   # Returns samples of window number <window-number> and true or false whether it's the last window \n",
    "    begin = window_number * (WINDOW_SIZE_SAMPLES - OVERLAPPING_SAMPLES)\n",
    "    end = begin + WINDOW_SIZE_SAMPLES\n",
    "    \n",
    "    if end < len(signal): # Commonly\n",
    "        return False, audio[begin:end]\n",
    "    else: # The window surpasses the audio data => Complete last elements of the window with zeros\n",
    "        return True, np.concatenate([audio[begin:len(signal)-1],np.zeros(end-len(signal)+1,dtype=float)])\n",
    "\n",
    "def detect_note_1(fft):                                                       # Returns the most suitable note for a given fft\n",
    "    freqs = np.fft.rfftfreq(WINDOW_SIZE_SAMPLES, 1/SAMPLE_RATE) # The array of frequencies to evaluate in the fft\n",
    "    F = np.abs(fft.real) # Evaluations of those frequencies\n",
    "    \n",
    "    if np.max(F) < INTENSITY_THRESHOLD: # If there are not high enough maximums, we cannot know\n",
    "        return \"Unknown\"\n",
    "    else:\n",
    "        n = freq_to_number(freqs[np.argmax(F)]) # Midi number of absolute maximum's frequency \n",
    "        n_approx = int(round(n)) # Round the midi number to fit a note\n",
    "        return note_name(n_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc40adfa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Main 1\n",
    "def main_1():\n",
    "    hanning = 0.5 * (1 - np.cos(np.linspace(0,2*np.pi,WINDOW_SIZE_SAMPLES,False)))  # The hanning window function\n",
    "\n",
    "    notes = []\n",
    "    window_number = 0\n",
    "    last_window = False\n",
    "    while not(last_window):\n",
    "        last_window, window = extract_window(signal, window_number)\n",
    "        window_number += 1\n",
    "\n",
    "        fft = np.fft.rfft(window * hanning)\n",
    "        notes.append(detect_note_1(fft))\n",
    "        \n",
    "    print(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "808eabc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C5', 'C4', 'C4', 'C4', 'C5', 'C5', 'C5', 'C4', 'C5', 'G5', 'D4', 'D4', 'D5', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D5', 'D4', 'D4', 'D5', 'D4', 'F4', 'E6', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'B1', 'D#0', 'F4', 'F4', 'F4', 'F4', 'F4', 'F5', 'F5', 'F5', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'G#4', 'D6', 'G4', 'G5', 'G4', 'G5', 'G4', 'G5', 'G4', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A5', 'D#0', 'D#0', 'D#0', 'A1', 'D#0', 'D#0', 'B4', 'B4', 'B4', 'B4', 'B5', 'B4', 'B4', 'B4', 'B4', 'F#6', 'B4', 'B4', 'B5', 'B4', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'B4', 'C5', 'C5', 'C5', 'C5', 'C6', 'C5', 'C6', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B5', 'B4', 'A1', 'B4', 'B4', 'A1', 'D#0', 'D#0', 'A4', 'A4', 'A4', 'A4', 'A5', 'A5', 'A5', 'E6', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'B1', 'B1', 'B1', 'G#4', 'G4', 'G5', 'G4', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G4', 'G5', 'B1', 'G5', 'G4', 'G5', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F5', 'F5', 'F5', 'F5', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'E5', 'E4', 'E6', 'E5', 'E6', 'E5', 'E6', 'E6', 'E5', 'E6', 'B5', 'A1', 'D#0', 'D#0', 'D#0', 'D#0', 'A1', 'E6', 'D4', 'D4', 'D4', 'F#6', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D5', 'D4', 'D4', 'D5', 'D4', 'C4', 'C4', 'C4', 'C4', 'C5', 'C4', 'C4', 'C4', 'C5', 'C4', 'C5', 'C4', 'C4', 'C5', 'A1', 'G5', 'C4', 'G5', 'G5', 'D#0', 'C5', 'D#0', 'G5', 'C5', 'D#0', 'D#0']\n"
     ]
    }
   ],
   "source": [
    "main_1()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0eae5d9",
   "metadata": {},
   "source": [
    "Segunda aproximación: Hallar el primer máximo de la fft en cada ventana, entre los puntos cuya evaluación se encuentre por encima de la media de las evaluaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "102c9aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions 2\n",
    "def graph2D_T_old(X,Y,threshold,file):\n",
    "    plt.figure()\n",
    "    sns.set_style('darkgrid')\n",
    "    sns.lineplot(x=X,y=Y,color='g')\n",
    "    sns.lineplot(x=X,y=np.full(len(X),threshold),color='r')\n",
    "    plt.savefig(file)\n",
    "    plt.close()\n",
    "\n",
    "def graph2D_T(x,y,threshold,file):\n",
    "    rcParams['font.family'] = 'Book Antiqua'\n",
    "    fig,ax = plt.subplots()\n",
    "    ax.plot(x,y,label='Módulo de la FFT',color='black')\n",
    "    ax.plot(x,np.full(len(y),threshold),label='Umbral',color='red')\n",
    "    ax.set_title('Módulo de la FFT')\n",
    "    ax.set_xlabel('Frecuencias')\n",
    "    ax.set_ylabel('Intensidad')\n",
    "    ax.grid(True);\n",
    "    fig.savefig(file)\n",
    "    plt.close(fig)\n",
    "    \n",
    "def first_maximum(freqs,F):                                                   # Returns frequency of first maximum\n",
    "    max_threshold = (np.max(F) + np.min(F))/2 # Threshold for the max\n",
    "    maximums = []\n",
    "    \n",
    "    for i in range(1,len(F)):\n",
    "        if F[i] > max_threshold and ((i == 0 and F[i+1] < F[i]) or (0 < i and i < len(F) and F[i-1] < F[i] and F[i+1] < F[i]) or (i == len(F)-1 and F[i-1] < F[i])):\n",
    "            maximums.append(i)\n",
    "    \n",
    "    return freqs[min(maximums)]\n",
    "    \n",
    "def detect_note_2(fft,wnum):                                                       # Returns the most suitable note for a given fft\n",
    "    freqs = np.fft.rfftfreq(WINDOW_SIZE_SAMPLES, 1/SAMPLE_RATE) # The array of frequencies to evaluate in the fft\n",
    "    F = np.abs(fft.real) # Evaluations of those frequencies\n",
    "    graph2D_T(freqs[0:1000],F[0:1000],(np.max(F) + np.min(F))/2,\"Plots\\\\w\" + str(wnum) + \"_V2.pdf\")\n",
    "    \n",
    "    if np.max(F) < INTENSITY_THRESHOLD: # If there are not high enough maximums, we cannot know\n",
    "        return \"Unknown\"\n",
    "    else:\n",
    "        n = freq_to_number(first_maximum(freqs,F)) # Midi number of absolute maximum's frequency \n",
    "        n_approx = int(round(n)) # Round the midi number to fit a note\n",
    "        return note_name(n_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ff52225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main 2\n",
    "def main_2():\n",
    "    hanning = 0.5 * (1 - np.cos(np.linspace(0,2*np.pi,WINDOW_SIZE_SAMPLES,False)))  # The hanning window function\n",
    "\n",
    "    notes = []\n",
    "    window_number = 0\n",
    "    last_window = False\n",
    "    while not(last_window):\n",
    "        last_window, window = extract_window(signal, window_number)\n",
    "        window_number += 1\n",
    "\n",
    "        fft = np.fft.rfft(window * hanning)\n",
    "        notes.append(detect_note_2(fft,window_number))\n",
    "        \n",
    "    print(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "456d4b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'D#0', 'D#0', 'D#0', 'D4', 'C#4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D5', 'D4', 'D4', 'D#0', 'D4', 'D4', 'D#4', 'F4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E5', 'E5', 'E5', 'A1', 'E5', 'A1', 'E5', 'D#0', 'D#0', 'D#0', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F5', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F#4', 'G4', 'G4', 'G5', 'G4', 'G4', 'G4', 'G5', 'G4', 'G4', 'G4', 'G5', 'G4', 'A1', 'G5', 'D#0', 'G4', 'G4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'A1', 'B4', 'B4', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C6', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'A1', 'D#0', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'A1', 'B4', 'B4', 'B4', 'B4', 'A1', 'B1', 'B4', 'D#0', 'D#0', 'D#0', 'G#4', 'A4', 'A4', 'A4', 'A4', 'A5', 'A5', 'D#0', 'B1', 'A4', 'A4', 'A4', 'A4', 'A4', 'A1', 'B1', 'F#1', 'D#0', 'F4', 'G4', 'G5', 'G4', 'G4', 'G4', 'G5', 'G4', 'G4', 'G5', 'G1', 'G4', 'G4', 'G5', 'B1', 'B1', 'B1', 'C2', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F5', 'F5', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'D#4', 'F4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E5', 'E5', 'D#0', 'B5', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'D4', 'D4', 'D4', 'F#6', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D#0', 'D4', 'D4', 'D#0', 'D4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C5', 'D#0', 'C5', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0', 'D#0']\n"
     ]
    }
   ],
   "source": [
    "main_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4d6641",
   "metadata": {},
   "source": [
    "Tercera aproximación: Hallar la fundamental en cada ventana como la frecuencia con mayor altura media en el conjunto de sus armónicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99ec068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions 3    \n",
    "def fund_freq(freqs,F):                                                   # Returns estimate fundamental frequency\n",
    "    means = np.array([])\n",
    "    \n",
    "    for i in range(1,len(F)):\n",
    "        if F[i] <= INTENSITY_THRESHOLD:\n",
    "            means = np.append(means,0)\n",
    "        else:\n",
    "            nharmonics = 1\n",
    "            mean = 0\n",
    "            harmonic = nharmonics * freqs[i]\n",
    "            top_freq = (len(F)-1) * freqs[1] \n",
    "            while harmonic <= top_freq:\n",
    "                h_pos = (np.abs(freqs - harmonic)).argmin()\n",
    "                mean += F[h_pos]\n",
    "                nharmonics += 1\n",
    "                harmonic = nharmonics * freqs[i]\n",
    "            \n",
    "            mean = mean / nharmonics\n",
    "            means = np.append(means,mean)\n",
    "                \n",
    "    return freqs[means.argmax()+1]\n",
    "    \n",
    "def detect_note_3(fft,wnum):                                                       # Returns the most suitable note for a given fft\n",
    "    freqs = np.fft.rfftfreq(WINDOW_SIZE_SAMPLES, 1/SAMPLE_RATE) # The array of frequencies to evaluate in the fft\n",
    "    F = np.abs(fft.real) # Evaluations of those frequencies\n",
    "    graph2D(freqs[0:500],F[0:500],\"Plots\\\\w\" + str(wnum) + \"_V3.pdf\")\n",
    "    \n",
    "    if np.max(F) < INTENSITY_THRESHOLD: # If there are not high enough maximums, we cannot know\n",
    "        return \"Unknown\"\n",
    "    else:\n",
    "        n = freq_to_number(fund_freq(freqs,F)) # Midi number of absolute maximum's frequency \n",
    "        n_approx = int(round(n)) # Round the midi number to fit a note\n",
    "        return note_name(n_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1feaab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main 3\n",
    "def main_3():\n",
    "    hanning = 0.5 * (1 - np.cos(np.linspace(0,2*np.pi,WINDOW_SIZE_SAMPLES,False)))  # The hanning window function\n",
    "\n",
    "    notes = []\n",
    "    window_number = 0\n",
    "    last_window = False\n",
    "    while not(last_window):\n",
    "        last_window, window = extract_window(signal, window_number)\n",
    "        window_number += 1\n",
    "\n",
    "        fft = np.fft.rfft(window * hanning)\n",
    "        notes.append(detect_note_3(fft,window_number))\n",
    "        \n",
    "    print(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ec249818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C4', 'C4', 'C4', 'C4', 'C5', 'E6', 'C5', 'C5', 'G5', 'C5', 'C5', 'A#6', 'C5', 'A#6', 'C5', 'G5', 'A#6', 'D4', 'F#6', 'D4', 'D4', 'F#6', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D5', 'D4', 'D4', 'D5', 'D4', 'E5', 'E6', 'E5', 'E6', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'B6', 'E5', 'B6', 'E7', 'F4', 'F4', 'F4', 'F4', 'F4', 'F5', 'F5', 'F5', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'D6', 'D7', 'G4', 'G5', 'D6', 'G5', 'D7', 'G5', 'D7', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'D7', 'G5', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A5', 'A5', 'A4', 'A4', 'A4', 'A4', 'B4', 'B4', 'B4', 'B4', 'B5', 'B4', 'B4', 'B6', 'B4', 'F#6', 'B4', 'B4', 'B5', 'B4', 'B4', 'B5', 'B4', 'B4', 'B5', 'C6', 'G6', 'C5', 'G6', 'C5', 'G6', 'C5', 'G6', 'C5', 'G6', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'B4', 'B4', 'B4', 'B4', 'F#7', 'B4', 'B4', 'B6', 'B4', 'B4', 'B4', 'B4', 'B5', 'B4', 'B4', 'F#6', 'B4', 'B4', 'A4', 'A4', 'A4', 'A4', 'A5', 'A5', 'A5', 'E6', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A5', 'A5', 'D6', 'G4', 'G5', 'D7', 'G5', 'D7', 'G5', 'G5', 'G5', 'G5', 'D7', 'G5', 'G4', 'G5', 'F7', 'G5', 'F7', 'G5', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F5', 'F5', 'F5', 'F5', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'E4', 'E5', 'E6', 'E6', 'E5', 'E6', 'E5', 'E6', 'E6', 'B6', 'E6', 'E6', 'B6', 'E6', 'B6', 'E7', 'B6', 'E6', 'E6', 'C7', 'D4', 'D4', 'F#6', 'D4', 'D4', 'D6', 'D4', 'D4', 'D4', 'D4', 'D6', 'D4', 'D4', 'D5', 'D4', 'D4', 'D5', 'D4', 'C5', 'C4', 'C5', 'C4', 'C5', 'C5', 'C4', 'C4', 'C5', 'E6', 'C5', 'A#6', 'C5', 'A#6', 'C6', 'G5', 'A#6', 'C5', 'E6', 'D7', 'G5', 'E6', 'G5', 'E6', 'E6', 'C5']\n"
     ]
    }
   ],
   "source": [
    "main_3()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01be89df",
   "metadata": {},
   "source": [
    "Cuarta aproximación: Hallar la fundamental en cada ventana como la frecuencia con mayor altura media en sus primeros armónicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b75d1f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "NUM_FIRST_HARMONICS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1e7c5a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions 4\n",
    "def fund_freq_2(freqs,F):                                                   # Returns estimate fundamental frequency\n",
    "    means = np.array([])\n",
    "    \n",
    "    for i in range(1,len(F)):\n",
    "        if F[i] <= INTENSITY_THRESHOLD:\n",
    "            means = np.append(means,0)\n",
    "        else:\n",
    "            nharmonics = 1\n",
    "            mean = 0\n",
    "            harmonic = nharmonics * freqs[i]\n",
    "            top_freq = (len(F)-1) * freqs[1] \n",
    "            while harmonic <= top_freq and nharmonics <= NUM_FIRST_HARMONICS:\n",
    "                h_pos = (np.abs(freqs - harmonic)).argmin()\n",
    "                mean += F[h_pos]\n",
    "                nharmonics += 1\n",
    "                harmonic = nharmonics * freqs[i]\n",
    "            \n",
    "            mean = mean / nharmonics\n",
    "            means = np.append(means,mean)\n",
    "\n",
    "    return freqs[means.argmax()+1]\n",
    "    \n",
    "def detect_note_4(fft,wnum):                                                       # Returns the most suitable note for a given fft\n",
    "    freqs = np.fft.rfftfreq(WINDOW_SIZE_SAMPLES, 1/SAMPLE_RATE) # The array of frequencies to evaluate in the fft\n",
    "    F = np.abs(fft.real) # Evaluations of those frequencies\n",
    "    #graph2D(freqs[0:500],F[0:500],\"Plots\\\\w\" + str(wnum) + \"_V4\")\n",
    "    \n",
    "    if np.max(F) < INTENSITY_THRESHOLD: # If there are not high enough maximums, we cannot know\n",
    "        return \"Unknown\"\n",
    "    else:\n",
    "        n = freq_to_number(fund_freq_2(freqs,F)) # Midi number of absolute maximum's frequency \n",
    "        n_approx = int(round(n)) # Round the midi number to fit a note\n",
    "        return note_name(n_approx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25089204",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main 4\n",
    "def main_4():\n",
    "    hanning = 0.5 * (1 - np.cos(np.linspace(0,2*np.pi,WINDOW_SIZE_SAMPLES,False)))  # The hanning window function\n",
    "\n",
    "    notes = []\n",
    "    window_number = 0\n",
    "    last_window = False\n",
    "    while not(last_window):\n",
    "        last_window, window = extract_window(signal, window_number)\n",
    "        window_number += 1\n",
    "\n",
    "        fft = np.fft.rfft(window * hanning)\n",
    "        notes.append(detect_note_4(fft,window_number))\n",
    "        \n",
    "    print(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a014adf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C5', 'C4', 'C4', 'C4', 'C4', 'C5', 'C4', 'C4', 'C3', 'D#-1', 'D3', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'B0', 'D#0', 'D#-1', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'G#4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G5', 'G4', 'G4', 'G4', 'G5', 'G4', 'G4', 'G4', 'D#0', 'G4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'D#-1', 'D#-1', 'D#-1', 'D#-1', 'D#-1', 'D#-1', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'D#-1', 'D#-1', 'D#-1', 'D#-1', 'D#-1', 'D#-1', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'D#-1', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'D#0', 'D#-1', 'D#-1', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'B0', 'B0', 'B0', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G3', 'G5', 'D#0', 'G4', 'G4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'E4', 'E5', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'D#-1', 'D#-1', 'D#-1', 'D#0', 'D#-1', 'B1', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D#-1', 'D4', 'D4', 'D4', 'D4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'D#0', 'C4', 'D#-1', 'C4', 'C4', 'D#-1', 'D#-1', 'D#-1', 'D#0', 'D#0', 'D#0', 'D#-1']\n"
     ]
    }
   ],
   "source": [
    "main_4()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2250f05d",
   "metadata": {},
   "source": [
    "Quinta aproximación: Hallar la fundamental, de entre las frecuencias del sistema temperado, como aquella de mayor altura media en el conjunto de sus armónicos (siendo la altura de una frecuencia no conocida la media ponderada por la distancia de las alturas de las dos frecuencias conocidas más cercanas a ella)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53d998a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global variables\n",
    "MIN_MIDI_NUM = 21\n",
    "MAX_MIDI_NUM = 108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d8b3f9b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions 5\n",
    "def indexes(freqs,i1,i2,harmonic):                                         # Returns h1 and h2 indexes of the nearest two \n",
    "    if i2-i1 == 1:                                                         #     harmonics of window's fund. to harmonic or\n",
    "        if harmonic == freqs[i1]:                                          #     h1 the index of harmonic in freqs and h2<0\n",
    "            return i1,-1\n",
    "        elif harmonic == freqs[i2]:\n",
    "            return i2,-1\n",
    "        else:\n",
    "            return i1,i2\n",
    "    else:\n",
    "        isplit = int(i1 + np.ceil((i2-i1)/2.0))\n",
    "        if harmonic < freqs[isplit]:\n",
    "            return indexes(freqs,i1,isplit,harmonic)\n",
    "        elif harmonic > freqs[isplit]:\n",
    "            return indexes(freqs,isplit,i2,harmonic)\n",
    "        else:\n",
    "            return isplit,-1\n",
    "\n",
    "def fund_freq_3(freqs,F):                                                  # Returns estimate fundamental frequency\n",
    "    means = np.array([])\n",
    "    \n",
    "    for i in range(MIN_MIDI_NUM,MAX_MIDI_NUM+1):\n",
    "        fund = number_to_freq(i)\n",
    "        nharmonics = 1\n",
    "        mean = 0\n",
    "        harmonic = nharmonics * fund\n",
    "        top_freq = (len(F)-1) * freqs[1] \n",
    "        while harmonic <= top_freq:\n",
    "            # Compute the indexes of the nearest two harmonics of window's fund. to harmonic\n",
    "            h1,h2 = indexes(freqs,0,len(freqs)-1,harmonic) \n",
    "            if h2 < 0:\n",
    "                if harmonic == fund and F[h1] <= INTENSITY_THRESHOLD: # Don't compute for powerless fundamentals\n",
    "                    mean = 0\n",
    "                    break\n",
    "                    \n",
    "                mean += F[h1]\n",
    "            else:\n",
    "                # Weighted mean of F[h1] and F[h2] by distance of freqs[h1] and freqs[h2] to the harmonic\n",
    "                mean += (F[h1]*np.log2(freqs[h2]/harmonic) + F[h2]*np.log2(harmonic/freqs[h1])) / np.log2(freqs[h2]/freqs[h1]) \n",
    "                     \n",
    "            nharmonics += 1\n",
    "            harmonic = nharmonics * fund\n",
    "\n",
    "        mean = mean / np.power(nharmonics,0.5)\n",
    "        means = np.append(means,mean)\n",
    "\n",
    "    return means.argmax()+MIN_MIDI_NUM\n",
    "    \n",
    "def detect_note_5(fft,wnum):                                               # Returns the most suitable note for a given fft\n",
    "    freqs = np.fft.rfftfreq(WINDOW_SIZE_SAMPLES, 1/SAMPLE_RATE) # The array of frequencies to evaluate in the fft\n",
    "    F = np.abs(fft.real) # Evaluations of those frequencies\n",
    "    graph2D(freqs[0:500],F[0:500],\"Plots\\\\w\" + str(wnum) + \"_V5.pdf\")\n",
    "    \n",
    "    if np.max(F) < INTENSITY_THRESHOLD: # If there are not high enough maximums, we cannot know\n",
    "        return \"Unknown\"\n",
    "    else:\n",
    "        n = fund_freq_3(freqs,F) # Midi number of absolute maximum's frequency\n",
    "        return note_name(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e89405b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main 5\n",
    "def main_5():\n",
    "    hanning = 0.5 * (1 - np.cos(np.linspace(0,2*np.pi,WINDOW_SIZE_SAMPLES,False)))  # The hanning window function\n",
    "\n",
    "    notes = []\n",
    "    window_number = 0\n",
    "    last_window = False\n",
    "    while not(last_window):\n",
    "        last_window, window = extract_window(signal,window_number)\n",
    "        window_number += 1\n",
    "\n",
    "        fft = np.fft.rfft(window * hanning)\n",
    "        notes.append(detect_note_5(fft,window_number))\n",
    "        \n",
    "    print(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7c815565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'A#0', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D5', 'D4', 'D4', 'D4', 'D4', 'C1', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E5', 'E5', 'E4', 'A0', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F5', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'B0', 'G4', 'G4', 'G5', 'G4', 'G4', 'G4', 'G5', 'G4', 'G4', 'G4', 'G5', 'G4', 'G4', 'G4', 'G4', 'G4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A5', 'A4', 'A4', 'A4', 'A4', 'A4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B5', 'B4', 'B4', 'B4', 'B4', 'B4', 'A0', 'A0', 'D1', 'C5', 'C5', 'C5', 'C5', 'C5', 'C6', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'A1', 'B4', 'B4', 'A#0', 'B0', 'A4', 'A4', 'A4', 'A4', 'A5', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A0', 'C1', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G5', 'G4', 'G4', 'G4', 'C1', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F5', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'A0', 'F1', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E5', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'A0', 'A1', 'A0', 'D4', 'D4', 'D4', 'F#6', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D5', 'D4', 'D4', 'D5', 'D4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'A#0', 'F1']\n"
     ]
    }
   ],
   "source": [
    "main_5()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c9a587",
   "metadata": {},
   "source": [
    "Sexta aproximación: Hallar la fundamental, de entre las frecuencias del sistema temperado, como aquella de mayor altura media en el conjunto de sus primeros armónicos (siendo la altura de una frecuencia no conocida la media ponderada por la distancia de las alturas de las dos frecuencias conocidas más cercanas a ella)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "895bc8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "NUM_FIRST_HARMONICS = 5\n",
    "# Global variables\n",
    "MIN_MIDI_NUM = 21\n",
    "MAX_MIDI_NUM = 108"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "edddc6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions 6\n",
    "def fund_freq_4(freqs,F,wnum):                                                  # Returns estimate fundamental frequency\n",
    "    means = np.array([])\n",
    "    \n",
    "    for i in range(MIN_MIDI_NUM,MAX_MIDI_NUM+1):\n",
    "        fund = number_to_freq(i)\n",
    "        nharmonics = 1\n",
    "        mean = 0\n",
    "        harmonic = nharmonics * fund\n",
    "        top_freq = (len(F)-1) * freqs[1] \n",
    "        while harmonic <= top_freq and nharmonics < NUM_FIRST_HARMONICS:\n",
    "            # Compute the indexes of the nearest two harmonics of window's fund. to harmonic\n",
    "            h1,h2 = indexes(freqs,0,len(freqs)-1,harmonic) \n",
    "            if h2 < 0:\n",
    "                if harmonic == fund and F[h1] <= INTENSITY_THRESHOLD: # Don't compute for powerless fundamentals\n",
    "                    mean = 0\n",
    "                    break\n",
    "                    \n",
    "                mean += F[h1]\n",
    "            else:\n",
    "                # Weighted mean of F[h1] and F[h2] by distance of freqs[h1] and freqs[h2] to the harmonic\n",
    "                mean += (F[h1]*np.log2(freqs[h2]/harmonic) + F[h2]*np.log2(harmonic/freqs[h1])) / np.log2(freqs[h2]/freqs[h1])\n",
    "                    \n",
    "            nharmonics += 1\n",
    "            harmonic = nharmonics * fund\n",
    "\n",
    "        mean = mean / np.power(nharmonics,0.5)\n",
    "        means = np.append(means,mean)\n",
    "\n",
    "    return means.argmax()+MIN_MIDI_NUM\n",
    "    \n",
    "def detect_note_6(fft,wnum):                                               # Returns the most suitable note for a given fft\n",
    "    freqs = np.fft.rfftfreq(WINDOW_SIZE_SAMPLES, 1/SAMPLE_RATE) # The array of frequencies to evaluate in the fft\n",
    "    F = np.power(np.abs(fft.real),2) # Evaluations of those frequencies\n",
    "    #graph2D(freqs[0:500],F[0:500],\"Plots\\\\w\" + str(wnum) + \"_V6\")\n",
    "    \n",
    "    if np.max(F) < INTENSITY_THRESHOLD: # If there are not high enough maximums, we cannot know\n",
    "        return \"Unknown\"\n",
    "    else:\n",
    "        n = fund_freq_4(freqs,F,wnum) # Midi number of absolute maximum's frequency \n",
    "        return note_name(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "85acab8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main 6\n",
    "def main_6():\n",
    "    hanning = 0.5 * (1 - np.cos(np.linspace(0,2*np.pi,WINDOW_SIZE_SAMPLES,False)))  # The hanning window function\n",
    "\n",
    "    notes = []\n",
    "    window_number = 0\n",
    "    last_window = False\n",
    "    while not(last_window):\n",
    "        last_window, window = extract_window(signal,window_number)\n",
    "        window_number += 1\n",
    "\n",
    "        fft = np.fft.rfft(window * hanning)\n",
    "        notes.append(detect_note_6(fft,window_number))\n",
    "        \n",
    "    print(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cb5366cf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'D4', 'D4', 'D4', 'D4', 'D4', 'G2', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'G2', 'D4', 'D4', 'D3', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'A#2', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'C#3', 'G4', 'G4', 'C4', 'G4', 'G4', 'G4', 'C4', 'G4', 'G4', 'G4', 'C4', 'G4', 'G4', 'C4', 'G4', 'G4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A0', 'A4', 'A4', 'E3', 'E3', 'B4', 'E3', 'B4', 'B4', 'B4', 'E3', 'E3', 'B4', 'B4', 'B4', 'E4', 'B4', 'B4', 'A0', 'A0', 'A0', 'A0', 'C5', 'C5', 'F3', 'F3', 'F3', 'C4', 'F3', 'F4', 'F3', 'C3', 'F3', 'F3', 'F3', 'F3', 'F3', 'F3', 'F3', 'F3', 'E3', 'E3', 'B4', 'E3', 'B4', 'E3', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'A0', 'B4', 'B4', 'A0', 'B4', 'B4', 'G#3', 'D3', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A#0', 'A#0', 'B0', 'G#2', 'G4', 'C4', 'G4', 'G4', 'G4', 'C4', 'G4', 'G4', 'C4', 'G4', 'G4', 'G4', 'C4', 'A#0', 'G4', 'G4', 'C4', 'A#2', 'F4', 'A#2', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'A#2', 'A#2', 'F4', 'F4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'A0', 'E4', 'E4', 'E4', 'A#0', 'A0', 'E4', 'D4', 'D4', 'D4', 'F#4', 'D4', 'D4', 'D4', 'G2', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D3', 'D4', 'D4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'A0', 'C4', 'C4', 'C4', 'C4', 'A0', 'C4', 'C4', 'C4', 'C4', 'B0', 'F1']\n"
     ]
    }
   ],
   "source": [
    "main_6()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be548c2e",
   "metadata": {},
   "source": [
    "Séptima aproximación: Autocorrelación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5fa7f4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions 7\n",
    "def ac1(window):\n",
    "    ac = []\n",
    "    s = 0\n",
    "    for i in range(0,len(window)):\n",
    "        for j in range(0,len(window)):\n",
    "            s += window[j] * window[(j+i)%len(window)]\n",
    "        ac.append(s)\n",
    "        s = 0\n",
    "    return ac\n",
    "\n",
    "def ac2(window):\n",
    "    ac = np.correlate(window,window,mode='full')\n",
    "    return ac[int(len(ac)/2):]\n",
    "\n",
    "def autocorrelation(window): # Fastest\n",
    "    ac = correlate(window,window,mode='full')\n",
    "    return ac[int(len(ac)/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8ea99b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main 7\n",
    "def main_7():\n",
    "    hanning = 0.5 * (1 - np.cos(np.linspace(0,2*np.pi,WINDOW_SIZE_SAMPLES,False)))  # The hanning window function\n",
    "\n",
    "    notes = []\n",
    "    window_number = 0\n",
    "    last_window = False\n",
    "    while not(last_window):\n",
    "        last_window, window = extract_window(signal,window_number)\n",
    "        window_number += 1\n",
    "        fft = np.fft.rfft(autocorrelation(window * hanning))\n",
    "        notes.append(detect_note_5(fft,window_number))\n",
    "        \n",
    "    print(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e35dfcf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E5', 'E5', 'E5', 'E5', 'E5', 'E4', 'E4', 'E4', 'E4', 'E4', 'A0', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'A0', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G5', 'G5', 'G5', 'G5', 'G5', 'G4', 'G4', 'G4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'A0', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'A1', 'B4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A0', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G5', 'G5', 'G5', 'G5', 'G5', 'G5', 'G4', 'G4', 'G4', 'G4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'A0', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'E5', 'A1', 'A1', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'A#0', 'A0']\n"
     ]
    }
   ],
   "source": [
    "main_7()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ffa632",
   "metadata": {},
   "source": [
    "Octava aproximación: Encontrar los picos relevantes (ignorar la intensidad de los picos) y estudiar qué frecuencia tiene mayor número de armónicos en dicho conjunto de picos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43013d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions 8\n",
    "def remove_duplicates(seq): # Remove duplicates preserving order\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "def detect_peaks(freqs,F): # Returns the array of freqs where fft has relevant peaks\n",
    "    pindex = find_peaks(F)\n",
    "    kmeans = KMeans(n_clusters=2,n_init=5,random_state=123456)\n",
    "    P = pd.DataFrame(data=[F[i] for i in pindex[0]],index=pindex[0],columns=['Intensity'])\n",
    "    clusters = kmeans.fit_predict(P) # Detect two clusters: peaks and non peaks\n",
    "    cluster_id = clusters[np.where(pindex[0] == np.argmax(F))[0][0]] # Cluster of peaks id\n",
    "    rpindex = np.where(clusters == cluster_id)[0] # Indexes of relevant peaks\n",
    "    return [freqs[i] for i in [pindex[0][j] for j in rpindex]]\n",
    "\n",
    "def find_candidates(cset): # Finds candidates for fundamental by substracting elements in cset\n",
    "    aux_cset = [c for c in cset if c >= 27.5] # Remove too low freqs\n",
    "    aux_cset.sort() # Order\n",
    "    aux_cset.insert(0,0) # Add 0 at the beginning\n",
    "    candidates = []\n",
    "    for i in range(0,len(aux_cset)):\n",
    "        for j in range(i+1,len(aux_cset)):\n",
    "            candidate = number_to_freq(int(round(freq_to_number(aux_cset[j] - aux_cset[i])))) # Round to equal temperament\n",
    "            if candidate not in candidates:\n",
    "                candidates.append(candidate)\n",
    "    return [c for c in candidates if c >= 27.5] # Remove too low freqs\n",
    "\n",
    "def count_harmonics(candidates): # Count the number of harmonics in candidates for each candidate\n",
    "    aux_candidates = candidates.copy()\n",
    "    aux_candidates.sort() # Order\n",
    "    nharmonics = np.zeros(len(aux_candidates),dtype=int)\n",
    "    for i in range(0,len(aux_candidates)):\n",
    "        for j in range(i,len(aux_candidates)):\n",
    "            div = np.modf(aux_candidates[j]/aux_candidates[i])[0]\n",
    "            if np.abs(div-round(div)) < 0.01: # Check if harmonic\n",
    "                nharmonics[i] += 1\n",
    "    return nharmonics\n",
    "\n",
    "def count_harmonics2(candidates,m): # Count the number of harmonics in candidates for each candidate\n",
    "    aux_candidates = candidates.copy()\n",
    "    aux_candidates.sort() # Order\n",
    "    nharmonics = np.zeros(len(aux_candidates),dtype=int)\n",
    "    for i in range(0,len(aux_candidates)):\n",
    "        for j in range(i,len(aux_candidates)):\n",
    "            div = np.modf(aux_candidates[j]/aux_candidates[i])[0]\n",
    "            if np.abs(div-round(div)) < 0.01: # Check if harmonic\n",
    "                nharmonics[i] += 1\n",
    "    for i in range(0,len(aux_candidates)):\n",
    "        samples = min(1,round(m/aux_candidates[i]))\n",
    "        nharmonics[i] /= np.sqrt(samples)\n",
    "    return nharmonics\n",
    "    \n",
    "def detect_note_7(fft,wnum):\n",
    "    freqs = np.fft.rfftfreq(WINDOW_SIZE_SAMPLES, 1/SAMPLE_RATE) # The array of frequencies to evaluate in the fft\n",
    "    F = np.abs(fft.real) # Evaluations of those frequencies\n",
    "    #graph2D(freqs[0:500],F[0:500],\"Plots\\\\w\" + str(wnum) + \"_V8\")\n",
    "    \n",
    "    peaks = [number_to_freq(round(freq_to_number(i))) for i in detect_peaks(freqs,F)] # Round to equal temperament\n",
    "    peaks = remove_duplicates(peaks) # Remove duplicates\n",
    "    \n",
    "    candidates = find_candidates(peaks)  \n",
    "    nharmonics = count_harmonics2(candidates,freqs[-1])\n",
    "    \n",
    "    candidates.sort()\n",
    "    \n",
    "    return note_name(int(round(freq_to_number(candidates[np.argmax(nharmonics)])))) if candidates else \"Unknown\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2256773d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main 8\n",
    "def main_8():\n",
    "    hanning = 0.5 * (1 - np.cos(np.linspace(0,2*np.pi,WINDOW_SIZE_SAMPLES,False)))  # The hanning window function\n",
    "\n",
    "    notes = []\n",
    "    window_number = 0\n",
    "    last_window = False\n",
    "    while not(last_window):\n",
    "        last_window, window = extract_window(signal,window_number)\n",
    "        window_number += 1\n",
    "        #print(\"Ventana \" + str(window_number))\n",
    "        fft = np.fft.rfft(window * hanning)\n",
    "        notes.append(detect_note_7(fft,window_number))\n",
    "        \n",
    "    print(notes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "096c4371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C1', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'E4', 'D#1', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E5', 'D5', 'E5', 'E4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F1', 'G4', 'G4', 'G5', 'G4', 'G4', 'G4', 'G5', 'G4', 'G4', 'G4', 'G5', 'G4', 'A1', 'G5', 'C3', 'A1', 'G1', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A1', 'A1', 'A5', 'A5', 'A1', 'A1', 'A1', 'A4', 'A#0', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'A1', 'B4', 'B4', 'A1', 'B5', 'A1', 'A1', 'A1', 'A#0', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C3', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'A1', 'B1', 'A#0', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B1', 'E2', 'B4', 'B1', 'A1', 'G#4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A5', 'A4', 'B1', 'A4', 'A4', 'A4', 'A4', 'A4', 'A1', 'B1', 'F#1', 'F#1', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G5', 'G4', 'G4', 'G5', 'G4', 'G4', 'G4', 'G5', 'G4', 'G4', 'G4', 'C2', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'D#1', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E5', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'Unknown', 'B1', 'A1', 'B1', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'B1', 'D4', 'D4', 'D4', 'D4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'B0', 'F#1']\n"
     ]
    }
   ],
   "source": [
    "main_8()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e837777",
   "metadata": {},
   "source": [
    "Novena aproximación: Mejora de la anterior. K-Means iterado sobre k hasta antes de superar un umbral de picos relevantes. Posteriormente, se aplica un proceso de corrección de notas teniendo en cuenta las anteriores a cada cual. Se añade un mecanismo de detección de silencio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a1b58923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "MAX_REL_PEAKS = 12 # Maximum number of peaks in the cluster of relevant peaks\n",
    "N_NOTES_CORRECTION_L = 4 # Number of notes to the left to consider for correcting a note\n",
    "N_NOTES_CORRECTION_R = 0 # Number of notes to the right to consider for correcting a note\n",
    "MAX_KM_ITERATIONS = 50 # Maximum number of K-Means iterations (> 0)\n",
    "MAX_CORRECTIONS = 1 # Maximum number of corrections\n",
    "SILENCE_THRESHOLD = 0.0001 # Intensity threshold for silence in [0,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f2e2c64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions 9  \n",
    "def remove_duplicates(seq): # Remove duplicates preserving order\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "def detect_peaks2(freqs,F): # Returns the array of freqs where fft has relevant peaks\n",
    "    peaks_before = []\n",
    "    peaks_after = []\n",
    "    pindex = find_peaks(F)\n",
    "    num_clusters = 2\n",
    "    nIterations = 0\n",
    "    P = pd.DataFrame(data=[F[i] for i in pindex[0]],index=pindex[0],columns=['Intensity'])\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=num_clusters,n_init=5,random_state=123456)\n",
    "    clusters = kmeans.fit_predict(P) # Detect two clusters: peaks and non peaks\n",
    "    cluster_id = clusters[np.argmin([F[i] for i in pindex[0]])] # Cluster of non relevant peaks id\n",
    "    rpindex = np.where(clusters != cluster_id)[0] # Indexes of relevant peaks\n",
    "    peaks_after = [freqs[i] for i in [pindex[0][j] for j in rpindex]]\n",
    "    num_clusters += 1\n",
    "    peaks_before = peaks_after.copy()\n",
    "    while len(peaks_after) <= MAX_REL_PEAKS and nIterations < MAX_KM_ITERATIONS:\n",
    "        peaks_before = peaks_after.copy()\n",
    "        nIterations += 1\n",
    "        kmeans = KMeans(n_clusters=num_clusters,n_init=5,random_state=123456)\n",
    "        clusters = kmeans.fit_predict(P) # Detect <num_clusters> clusters\n",
    "        cluster_id = clusters[np.argmin([F[i] for i in pindex[0]])] # Cluster of non relevant peaks id\n",
    "        rpindex = np.where(clusters != cluster_id)[0] # Indexes of relevant peaks\n",
    "        peaks_after = [freqs[i] for i in [pindex[0][j] for j in rpindex]]\n",
    "        num_clusters += 1\n",
    "        \n",
    "    return peaks_before\n",
    "\n",
    "def find_candidates2(cset): # Finds candidates for fundamental by substracting elements in cset\n",
    "    aux_cset = [c for c in cset if c >= 27.5].copy() # Remove too low freqs\n",
    "    aux_cset.sort() # Order\n",
    "    candidates = aux_cset.copy()\n",
    "    for i in range(0,len(aux_cset)-1):\n",
    "        candidate = number_to_freq(int(round(freq_to_number(aux_cset[i+1] - aux_cset[i])))) # Round to equal temperament\n",
    "        if candidate not in candidates:\n",
    "            candidates.append(candidate)\n",
    "    return [c for c in candidates if c >= 27.5] # Remove too low freqs\n",
    "\n",
    "def count_harmonics(candidates): # Count the number of harmonics in candidates for each candidate\n",
    "    aux_candidates = candidates.copy()\n",
    "    aux_candidates.sort() # Order\n",
    "    nharmonics = np.zeros(len(aux_candidates),dtype=int)\n",
    "    for i in range(0,len(aux_candidates)):\n",
    "        for j in range(i,len(aux_candidates)):\n",
    "            div = np.modf(aux_candidates[j]/aux_candidates[i])[0]\n",
    "            if np.abs(div-round(div)) < 0.01: # Check if harmonic\n",
    "                nharmonics[i] += 1\n",
    "    return nharmonics\n",
    "\n",
    "def count_harmonics2(candidates,m): # Count the number of harmonics in candidates for each candidate\n",
    "    aux_candidates = candidates.copy()\n",
    "    aux_candidates.sort() # Order\n",
    "    nharmonics = np.zeros(len(aux_candidates),dtype=float)\n",
    "    for i in range(0,len(aux_candidates)):\n",
    "        for j in range(i,len(aux_candidates)):\n",
    "            div = np.modf(aux_candidates[j]/aux_candidates[i])[0]\n",
    "            if np.abs(div-round(div)) < 0.01: # Check if harmonic\n",
    "                nharmonics[i] += 1\n",
    "    for i in range(0,len(aux_candidates)):\n",
    "        samples = max(1,round(m/aux_candidates[i]))\n",
    "        nharmonics[i] /= np.power(samples,0.1)\n",
    "        \n",
    "    return nharmonics\n",
    "\n",
    "def count_harmonics3(peaks,candidates,m): # Count the number of harmonics in peaks for each candidate\n",
    "    nharmonics = np.zeros(len(candidates),dtype=float)\n",
    "    for i in range(0,len(candidates)):\n",
    "        for j in range(0,len(peaks)):\n",
    "            if peaks[j] >= candidates[i]:\n",
    "                div = np.modf(peaks[j]/candidates[i])[0]\n",
    "                if np.abs(div-round(div)) < 0.01: # Check if harmonic\n",
    "                    nharmonics[i] += 1\n",
    "    for i in range(0,len(candidates)):\n",
    "        samples = max(1,round(m/candidates[i]))\n",
    "        nharmonics[i] /= np.power(samples,0.1)\n",
    "        \n",
    "    return nharmonics\n",
    "\n",
    "def max_amplitude(fund,freqs,F): # Compute the maximum of amplitudes in fund harmonics as weight of the note\n",
    "    max_amp = 0\n",
    "    num_harmonic = 1\n",
    "    harmonic = num_harmonic * fund\n",
    "    top_freq = (len(F)-1) * freqs[1] \n",
    "    while harmonic <= top_freq:\n",
    "        # Compute the indexes of the nearest two harmonics of window's fund. to harmonic\n",
    "        h1,h2 = indexes(freqs,0,len(freqs)-1,harmonic) \n",
    "        if h2 < 0:\n",
    "            max_amp = max([max_amp,F[h1]])\n",
    "        else:\n",
    "            # Weighted mean of F[h1] and F[h2] by distance of freqs[h1] and freqs[h2] to the harmonic\n",
    "            max_amp = max([max_amp,(F[h1]*np.log2(freqs[h2]/harmonic) + F[h2]*np.log2(harmonic/freqs[h1])) / np.log2(freqs[h2]/freqs[h1])]) \n",
    "\n",
    "        num_harmonic += 1\n",
    "        harmonic = num_harmonic * fund\n",
    "        \n",
    "    return max_amp\n",
    "    \n",
    "def detect_note_8(fft,wnum):\n",
    "    freqs = np.fft.rfftfreq(WINDOW_SIZE_SAMPLES, 1/SAMPLE_RATE) # The array of frequencies to evaluate in the fft\n",
    "    F = np.abs(fft.real) # Evaluations of those frequencies\n",
    "    #graph2D(freqs[0:500],F[0:500],\"Plots\\\\w\" + str(wnum) + \"_V9\")\n",
    "    \n",
    "    peaks = [number_to_freq(round(freq_to_number(i))) for i in detect_peaks2(freqs,F)] # Round to equal temperament\n",
    "    peaks = remove_duplicates(peaks) # Remove duplicates\n",
    "     \n",
    "    candidates = find_candidates2(peaks)\n",
    "    nharmonics = count_harmonics3(peaks,candidates,freqs[-1]) \n",
    "    \n",
    "    pred_fund = candidates[np.argmax(nharmonics)]\n",
    "\n",
    "    return (note_name(int(round(freq_to_number(pred_fund)))),max_amplitude(pred_fund,freqs,F))\n",
    "\n",
    "def correct_notes_iteration(notes,weights,nl,nr): # Correct each note according to its nl previous and nr following ones' weights\n",
    "    cnotes = notes.copy() # Necessary for keeping the first and last notes\n",
    "    cweights = weights.copy() # Necessary for keeping the first and last weights\n",
    "    \n",
    "    silence_threshold = SILENCE_THRESHOLD * max(cweights)\n",
    "    n = max(nl,nr)\n",
    "    w = [1] # New weights for the window, based on proximity to the note to be corrected\n",
    "    for k in range(1,n+1):\n",
    "        w.append(sum(w))\n",
    "        \n",
    "    for i in range(0,len(notes)-nr):\n",
    "        if cnotes[i] == 'S': # Avoid correcting silence\n",
    "            continue\n",
    "        if cweights[i] <= silence_threshold: # Correct as silence and keep the weight\n",
    "            cnotes[i] = 'S'\n",
    "            continue\n",
    "            \n",
    "        if i in range(0,nl) or i in range(len(notes)-nr,len(notes)): # Skip if cannot be corrected for being out of the range\n",
    "            continue\n",
    "        \n",
    "        nsubset = []\n",
    "        wsubset = []\n",
    "        nsums = []\n",
    "        for j in range(i-nl,i+nr+1):\n",
    "            if notes[j] not in nsubset:\n",
    "                nsubset.append(notes[j])\n",
    "                if j <= i:\n",
    "                    wsubset.append(w[j-(i-n)] * weights[j])\n",
    "                    nsums.append(w[j-(i-n)])\n",
    "                else:\n",
    "                    wsubset.append(w[i+n-j] * weights[j] / 2) # Little penalization to future notes\n",
    "                    nsums.append(w[i+n-j] / 2)\n",
    "            else:\n",
    "                if j <= i:\n",
    "                    wsubset[nsubset.index(notes[j])] += w[j-(i-n)] * weights[j]\n",
    "                    nsums[nsubset.index(notes[j])] += w[j-(i-n)]\n",
    "                else:\n",
    "                    wsubset[nsubset.index(notes[j])] += w[i+n-j] * weights[j] / 2\n",
    "                    nsums[nsubset.index(notes[j])] += w[i+n-j] / 2\n",
    "                  \n",
    "        index = len(wsubset) - wsubset[::-1].index(max(wsubset)) - 1 # Index of last maximum of wsubset\n",
    "        cnotes[i] = nsubset[index]\n",
    "        cweights[i] = wsubset[index] / nsums[index]\n",
    "        \n",
    "    return cnotes,cweights\n",
    "\n",
    "def correct_notes(notes,weights,nl,nr): # Correct the notes\n",
    "    count = 0\n",
    "    \n",
    "    notes_before = notes.copy()\n",
    "    notes_after,cweights = correct_notes_iteration(notes,weights,nl,nr)\n",
    "    while not np.array_equal(notes_before,notes_after) and count < MAX_CORRECTIONS:\n",
    "        notes_before = notes_after.copy()\n",
    "        count += 1\n",
    "        notes_after,cweights = correct_notes_iteration(notes_before,cweights,nl,nr)\n",
    "    \n",
    "    return notes_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04f2c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main 9\n",
    "def main_9():\n",
    "    hanning = 0.5 * (1 - np.cos(np.linspace(0,2*np.pi,WINDOW_SIZE_SAMPLES,False)))  # The hanning window function\n",
    "\n",
    "    notes = []\n",
    "    weights = []\n",
    "    window_number = 0\n",
    "    last_window = False\n",
    "    while not(last_window):\n",
    "        last_window, window = extract_window(signal,window_number)\n",
    "        window_number += 1\n",
    "        #print(\"Ventana \" + str(window_number))\n",
    "        fft = np.fft.rfft(autocorrelation(window * hanning))\n",
    "        note,weight = detect_note_8(fft,window_number)\n",
    "        notes.append(note)\n",
    "        weights.append(weight)\n",
    "        \n",
    "    cnotes = correct_notes(notes,weights,N_NOTES_CORRECTION_L,N_NOTES_CORRECTION_R)\n",
    "        \n",
    "    print(cnotes)\n",
    "    #print([(cnotes[i],i+1) for i in range(0,len(cnotes))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "58f29277",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A1', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'C5', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'B4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'A4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'G4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'F4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'E4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'D4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'C4', 'S', 'C4']\n"
     ]
    }
   ],
   "source": [
    "main_9()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f037a5a",
   "metadata": {},
   "source": [
    "Por curiosidad: En lugar del número de armónicos de cada candidato en los picos, contabilizar las diferencias entre cada par de picos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89144796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs\n",
    "PATH = 'C:\\\\Users\\\\Javier\\\\Desktop\\\\TFG\\\\ReconocimientoDeTonos'      # Path of project's directory\n",
    "AUDIO_FILE = 'DoM-piano.wav'                                         # Audio file's name\n",
    "WINDOW_SIZE_SECS = 0.2                                               # Size of the fft window in seconds\n",
    "OVERLAPPING_SECS = 0.15                                              # Window's overlapping in seconds\n",
    "SILENCE_THRESHOLD = 0.0001                                           # Intensity threshold for silence in [0,1]\n",
    "INTENSITY_THRESHOLD = 0.001                                          # Intensity (relevance) threshold for frequencies\n",
    "MAX_REL_PEAKS = 12                                                   # Maximum number of peaks in the cluster of relevant peaks\n",
    "N_NOTES_CORRECTION_L = 4                                             # Number of notes to the left to consider for correcting a note\n",
    "N_NOTES_CORRECTION_R = 0                                             # Number of notes to the right to consider for correcting a note\n",
    "MAX_KM_ITERATIONS = 50                                               # Maximum number of K-Means iterations\n",
    "MAX_CORRECTIONS = 1                                                  # Maximum number of corrections\n",
    "\n",
    "# Global variables \n",
    "NOTES = [\"C\",\"C#\",\"D\",\"D#\",\"E\",\"F\",\"F#\",\"G\",\"G#\",\"A\",\"A#\",\"B\"]       # The twelve notes' names\n",
    "SAMPLE_RATE, data = wavfile.read(os.path.join(PATH,AUDIO_FILE))      # Get sample rate (samples per second) and signal data\n",
    "signal = data if data.ndim == 1 else data.T[0]                       # Get the first channel\n",
    "WINDOW_SIZE_SAMPLES = int(SAMPLE_RATE * WINDOW_SIZE_SECS)            # Size of the fft window in samples\n",
    "OVERLAPPING_SAMPLES = int(SAMPLE_RATE * OVERLAPPING_SECS)            # Size of overlapping in samples\n",
    "AUDIO_SIZE_SECS = len(signal) / SAMPLE_RATE                          # Size of the audio file in seconds\n",
    "\n",
    "# Files' statistics\n",
    "print(\"Sample rate: \" + str(SAMPLE_RATE) + \" Hz\")                   \n",
    "print(\"Signal: \" + str(signal))                                      \n",
    "print(\"Window size: \" + str(WINDOW_SIZE_SECS) + \" s = \" + str(WINDOW_SIZE_SAMPLES) + \" samples\")\n",
    "print(\"Overlapping: \" + str(OVERLAPPING_SECS) + \" s = \" + str(OVERLAPPING_SAMPLES) + \" samples\")\n",
    "print(\"Audio length: \" + str(AUDIO_SIZE_SECS) + \" s\")\n",
    "\n",
    "# Functions\n",
    "def freq_to_number(f):                                                      # Transforms any note's frequency into its midi number \n",
    "    return 69 + 12*np.log2(f/440.0)    \n",
    "\n",
    "def number_to_freq(n):                                                      # Transforms any note's midi number into its frequency\n",
    "    return 440 * 2.0**((n-69)/12.0)\n",
    "\n",
    "def note_name(n):                                                           # Gets the note's name given its midi number\n",
    "    return NOTES[n % 12] + str(int(n/12 - 1))\n",
    "\n",
    "def extract_window(audio, window_number):                                   # Returns samples of window number <window-number> and true or false whether it's the last window \n",
    "    begin = window_number * (WINDOW_SIZE_SAMPLES - OVERLAPPING_SAMPLES)\n",
    "    end = begin + WINDOW_SIZE_SAMPLES\n",
    "    \n",
    "    if end < len(signal): # Commonly\n",
    "        return False, audio[begin:end]\n",
    "    else: # The window surpasses the audio data => Complete last elements of the window with zeros\n",
    "        return True, np.concatenate([audio[begin:len(signal)-1],np.zeros(end-len(signal)+1,dtype=float)])\n",
    "    \n",
    "def autocorrelation(window):                                                # Autocorrelation of a given window\n",
    "    ac = correlate(window,window,mode='full')\n",
    "    return ac[int(len(ac)/2):]\n",
    "    \n",
    "def indexes(freqs,i1,i2,harmonic):                                          # Returns h1 and h2 indexes of the nearest two \n",
    "    if i2-i1 == 1:                                                          #     harmonics of window's fund. to harmonic or\n",
    "        if harmonic == freqs[i1]:                                           #     h1 the index of harmonic in freqs and h2<0\n",
    "            return i1,-1\n",
    "        elif harmonic == freqs[i2]:\n",
    "            return i2,-1\n",
    "        else:\n",
    "            return i1,i2\n",
    "    else:\n",
    "        isplit = int(i1 + np.ceil((i2-i1)/2.0))\n",
    "        if harmonic < freqs[isplit]:\n",
    "            return indexes(freqs,i1,isplit,harmonic)\n",
    "        elif harmonic > freqs[isplit]:\n",
    "            return indexes(freqs,isplit,i2,harmonic)\n",
    "        else:\n",
    "            return isplit,-1\n",
    "        \n",
    "def remove_duplicates(seq): # Remove duplicates preserving order\n",
    "    seen = set()\n",
    "    seen_add = seen.add\n",
    "    return [x for x in seq if not (x in seen or seen_add(x))]\n",
    "\n",
    "def detect_peaks(freqs,F): # Returns the array of freqs where fft has relevant peaks\n",
    "    peaks_before = []\n",
    "    peaks_after = []\n",
    "    pindex = find_peaks(F)\n",
    "    if not len(pindex[0]):\n",
    "        return []\n",
    "    num_clusters = 2\n",
    "    nIterations = 0\n",
    "    P = pd.DataFrame(data=[F[i] for i in pindex[0]],index=pindex[0],columns=['Intensity'])\n",
    "    \n",
    "    kmeans = KMeans(n_clusters=num_clusters,n_init=5,random_state=123456)\n",
    "    clusters = kmeans.fit_predict(P) # Detect two clusters: peaks and non peaks\n",
    "    cluster_id = clusters[np.argmin([F[i] for i in pindex[0]])] # Cluster of non relevant peaks id\n",
    "    rpindex = np.where(clusters != cluster_id)[0] # Indexes of relevant peaks\n",
    "    peaks_after = [freqs[i] for i in [pindex[0][j] for j in rpindex]]\n",
    "    num_clusters += 1\n",
    "    peaks_before = peaks_after.copy()\n",
    "    while len(peaks_after) <= MAX_REL_PEAKS and nIterations < MAX_KM_ITERATIONS:\n",
    "        peaks_before = peaks_after.copy()\n",
    "        nIterations += 1\n",
    "        kmeans = KMeans(n_clusters=num_clusters,n_init=5,random_state=123456)\n",
    "        clusters = kmeans.fit_predict(P) # Detect <num_clusters> clusters\n",
    "        cluster_id = clusters[np.argmin([F[i] for i in pindex[0]])] # Cluster of non relevant peaks id\n",
    "        rpindex = np.where(clusters != cluster_id)[0] # Indexes of relevant peaks\n",
    "        peaks_after = [freqs[i] for i in [pindex[0][j] for j in rpindex]]\n",
    "        num_clusters += 1\n",
    "        \n",
    "    return peaks_before\n",
    "\n",
    "def find_candidates(cset): # Finds candidates for fundamental by substracting elements in cset\n",
    "    aux_cset = [c for c in cset if c >= 27.5].copy() # Remove too low freqs\n",
    "    aux_cset.sort() # Order\n",
    "    candidates = aux_cset.copy()\n",
    "    for i in range(0,len(aux_cset)-1):\n",
    "        candidate = number_to_freq(int(round(freq_to_number(aux_cset[i+1] - aux_cset[i])))) # Round to equal temperament\n",
    "        if candidate not in candidates:\n",
    "            candidates.append(candidate)\n",
    "    return [c for c in candidates if c >= 27.5] # Remove too low freqs\n",
    "\n",
    "def count_harmonics(peaks,candidates,m): # Count the number of harmonics in peaks for each candidate\n",
    "    nharmonics = np.zeros(len(candidates),dtype=float)\n",
    "    for i in range(0,len(candidates)):\n",
    "        for j in range(0,len(peaks)):\n",
    "            if peaks[j] >= candidates[i]:\n",
    "                div = np.modf(peaks[j]/candidates[i])[0]\n",
    "                if np.abs(div-round(div)) < 0.01: # Check if harmonic\n",
    "                    nharmonics[i] += 1\n",
    "    for i in range(0,len(candidates)):\n",
    "        samples = max(1,round(m/candidates[i]))\n",
    "        nharmonics[i] /= np.power(samples,0.1)\n",
    "        \n",
    "    return nharmonics\n",
    "\n",
    "def count_differences(peaks): # Count the number of harmonics in peaks for each candidate\n",
    "    aux_peaks = peaks.copy()\n",
    "    aux_peaks.sort()\n",
    "    aux_peaks.insert(0,0.0);\n",
    "    differences = []\n",
    "    counts = []\n",
    "    \n",
    "    for i in range(0,len(aux_peaks)):\n",
    "        for j in range(i+1,len(aux_peaks)):\n",
    "            diff = number_to_freq(int(round(freq_to_number(aux_peaks[j] - aux_peaks[i]))))\n",
    "            if diff not in differences:\n",
    "                differences.append(diff)\n",
    "                counts.append(1)\n",
    "            else:\n",
    "                counts[differences.index(diff)] += 1\n",
    "        \n",
    "    return differences[np.argmax(counts)]\n",
    "\n",
    "def max_amplitude(fund,freqs,F): # Compute the maximum of amplitudes in fund harmonics as weight of the note\n",
    "    max_amp = 0\n",
    "    num_harmonic = 1\n",
    "    harmonic = num_harmonic * fund\n",
    "    top_freq = (len(F)-1) * freqs[1] \n",
    "    while harmonic <= top_freq:\n",
    "        # Compute the indexes of the nearest two harmonics of window's fund. to harmonic\n",
    "        h1,h2 = indexes(freqs,0,len(freqs)-1,harmonic) \n",
    "        if h2 < 0:\n",
    "            max_amp = max([max_amp,F[h1]])\n",
    "        else:\n",
    "            # Weighted mean of F[h1] and F[h2] by distance of freqs[h1] and freqs[h2] to the harmonic\n",
    "            if freqs[h1] != 0:\n",
    "                max_amp = max([max_amp,(F[h1]*np.log2(freqs[h2]/harmonic) + F[h2]*np.log2(harmonic/freqs[h1])) / np.log2(freqs[h2]/freqs[h1])])\n",
    "\n",
    "        num_harmonic += 1\n",
    "        harmonic = num_harmonic * fund\n",
    "        \n",
    "    return max_amp\n",
    "    \n",
    "def detect_note(fft):\n",
    "    freqs = np.fft.rfftfreq(WINDOW_SIZE_SAMPLES, 1/SAMPLE_RATE) # The array of frequencies to evaluate in the fft\n",
    "    F = np.abs(fft.real) # Evaluations of those frequencies\n",
    "    \n",
    "    peaks = [number_to_freq(round(freq_to_number(i))) for i in detect_peaks(freqs,F)] # Round to equal temperament\n",
    "    if not len(peaks):\n",
    "        return ('S',0)\n",
    "    peaks = remove_duplicates(peaks) # Remove duplicates\n",
    "     \n",
    "    pred_fund = count_differences(peaks)\n",
    "    \n",
    "    return (note_name(int(round(freq_to_number(pred_fund)))),max_amplitude(pred_fund,freqs,F))\n",
    "\n",
    "def correct_notes_iteration(notes,weights,nl,nr): # Correct each note according to its nl previous and nr following ones' weights\n",
    "    cnotes = notes.copy() # Necessary for keeping the first and last notes\n",
    "    cweights = weights.copy() # Necessary for keeping the first and last weights\n",
    "    \n",
    "    silence_threshold = SILENCE_THRESHOLD * max(cweights)\n",
    "    n = max(nl,nr)\n",
    "    w = [1] # New weights for the window, based on proximity to the note to be corrected\n",
    "    for k in range(1,n+1):\n",
    "        w.append(sum(w))\n",
    "        \n",
    "    for i in range(0,len(notes)-nr):\n",
    "        if cnotes[i] == 'S': # Avoid correcting silence\n",
    "            continue\n",
    "        if cweights[i] <= silence_threshold: # Correct as silence and keep the weight\n",
    "            cnotes[i] = 'S'\n",
    "            continue\n",
    "            \n",
    "        if i in range(0,nl) or i in range(len(notes)-nr,len(notes)): # Skip if cannot be corrected for being out of the range\n",
    "            continue\n",
    "        \n",
    "        nsubset = []\n",
    "        wsubset = []\n",
    "        nsums = []\n",
    "        for j in range(i-nl,i+nr+1):\n",
    "            if notes[j] not in nsubset:\n",
    "                nsubset.append(notes[j])\n",
    "                if j <= i:\n",
    "                    wsubset.append(w[j-(i-n)] * weights[j])\n",
    "                    nsums.append(w[j-(i-n)])\n",
    "                else:\n",
    "                    wsubset.append(w[i+n-j] * weights[j] / 2) # Little penalization to future notes\n",
    "                    nsums.append(w[i+n-j] / 2)\n",
    "            else:\n",
    "                if j <= i:\n",
    "                    wsubset[nsubset.index(notes[j])] += w[j-(i-n)] * weights[j]\n",
    "                    nsums[nsubset.index(notes[j])] += w[j-(i-n)]\n",
    "                else:\n",
    "                    wsubset[nsubset.index(notes[j])] += w[i+n-j] * weights[j] / 2\n",
    "                    nsums[nsubset.index(notes[j])] += w[i+n-j] / 2\n",
    "                  \n",
    "        index = len(wsubset) - wsubset[::-1].index(max(wsubset)) - 1 # Index of last maximum of wsubset\n",
    "        cnotes[i] = nsubset[index]\n",
    "        cweights[i] = wsubset[index] / nsums[index]\n",
    "        \n",
    "    return cnotes,cweights\n",
    "\n",
    "def correct_notes(notes,weights,nl,nr): # Correct the notes\n",
    "    count = 0\n",
    "    \n",
    "    notes_before = notes.copy()\n",
    "    notes_after,cweights = correct_notes_iteration(notes,weights,nl,nr)\n",
    "    while not np.array_equal(notes_before,notes_after) and count < MAX_CORRECTIONS:\n",
    "        notes_before = notes_after.copy()\n",
    "        count += 1\n",
    "        notes_after,cweights = correct_notes_iteration(notes_before,cweights,nl,nr)\n",
    "    \n",
    "    return notes_before\n",
    "\n",
    "def notes_per_window():\n",
    "    hanning = 0.5 * (1 - np.cos(np.linspace(0,2*np.pi,WINDOW_SIZE_SAMPLES,False)))  # The hanning window function\n",
    "\n",
    "    notes = []\n",
    "    weights = []\n",
    "    window_number = 0\n",
    "    last_window = False\n",
    "    while not(last_window):\n",
    "        last_window, window = extract_window(signal,window_number)\n",
    "        window_number += 1\n",
    "        fft = np.fft.rfft(autocorrelation(window * hanning))\n",
    "        note,weight = detect_note(fft)\n",
    "        notes.append(note)\n",
    "        weights.append(weight)\n",
    "       \n",
    "    return correct_notes(notes,weights,N_NOTES_CORRECTION_L,N_NOTES_CORRECTION_R)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ee57a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "npw = notes_per_window()\n",
    "print(npw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
